# Разреженное извлечение
Ранжирование основано на лексическом соотвествии, не использует обученные модели.

## BM25 (+ WAND) 
Без алгоритма обрезания мы ранжируем сразу по всему, что на больших данных занимает слишком много времени. \
С высокой вероятностью мы упустим нужный источник.

## Динамический WAND
[Может быть полезно](https://www.researchgate.net/publication/221613425_Efficient_query_evaluation_using_a_two-level_retrieval_process)\
Согласно статье, этот метод работает кратно быстрее обычного BM25 и практически без потери точности. \ 
Минусы: мы не можем определять функцию оценки. \
0.16 @rank10.

# Плотное извлечение
Общая идея: Документы переводим в векторное пространство, затем ищем ближайших соседей.

## С использованием моделей типа Transformer
Среди интегрированных в Vespa есть модель, [основанная на MiniLM](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L-6-v3). \
Модель переводит в векторное пространство + HNSW (по сути, это NN). \
0.30 @rank10.

## С использованием ColBERT
Этот метод наиболее интегрирован в Vespa. Отличие от трансформеров в получаемом векторном пространстве. По точности немного выше, чем у предыдущего метода. 0.35 @rank10.

## Надстройка
Поверх последних двух методов мы можем использовать еще одну модель для более детальной оценки соответствия запросу. Точность повышается не сильно, но кратно вырастают требуемые вычислительные мощности. 0.39 @rank10.

# Гибрид двух последних 
[Статья](https://arxiv.org/abs/2104.05740). \
Этот метод работает быстрее, чем предыдущий метод, благодаря обрезанию пространства во время поиска ближайшего соседа. Насколько я нашел информацию, нет точных данных об эффективности и примерах, на что можно опираться при реализации этого метода.

## ColPaLi
[Ссылка 1](https://blog.vespa.ai/the-rise-of-vision-driven-document-retrieval-for-rag/),\
[Ссылка 2](https://medium.com/the-ai-forum/implement-multimodal-rag-with-colpali-and-vision-language-model-groq-llava-and-qwen2-vl-5c113b8c08fd). \
Если плотные подходы основаны на определенных обучениях модели MiniLM, то ColPaLi реализует подход индексации по визуальным признакам. \
В самой документации Vespa пока ничего не написано про интегрирование этой модели, и поэтому необходимо еще изучать как мы сможем ее использовать.

# Про методы оценки
При оценивании обычно используют метрику @rank10, которая определяет, есть ли найденный алгоритмом документ в топ-10 самых релевантных. \ 
Если же смотреть на метрики попадания в топ-100 или топ-1000, они растут экспоненциально, и к топ-1000 все предложенные методы выдают примерно 0,9 точности. Надо понимать, что метрики подходов были получены на датасете MS Marco с сотнями тысяч документов, и совсем не очевидно, что они сохранят соотношение точности в условиях вашей задачи.

## Встречаемые ссылки, на которые я обратил внимание и, возможно, которые стоит сохранить (пока их не классифицировал):

- https://habr.com/ru/articles/545634/
- https://arxiv.org/abs/2104.08663
- https://blog.google/products/search/search-language-understanding-bert/
- https://bergum.medium.com/how-not-to-use-bert-for-search-ranking-4586716428d9